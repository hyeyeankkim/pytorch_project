{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4707fcb1",
   "metadata": {},
   "source": [
    "# 국민청원 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d1a752",
   "metadata": {},
   "source": [
    "## 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c95e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www1.president.go.kr/petitions/594316\n",
      "https://www1.president.go.kr/petitions/594317\n",
      "https://www1.president.go.kr/petitions/594318\n",
      "https://www1.president.go.kr/petitions/594319\n",
      "https://www1.president.go.kr/petitions/594320\n"
     ]
    }
   ],
   "source": [
    "for i in range(594316,594321):\n",
    "    URL = \"https://www1.president.go.kr/petitions/\"+str(i)\n",
    "    print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6e0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for i in range(584274,595226):\n",
    "    URL = \"https://www1.president.go.kr/petitions/\"+str(i)\n",
    "    \n",
    "    response = requests.get(URL)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    title = soup.find('h3', class_ = 'petitionsView_title')\n",
    "    count  = soup.find('span',class_='counter')\n",
    "    \n",
    "    for content in soup.select('div.petitionsView_write > div.View_write'):\n",
    "        content\n",
    "        a=[]\n",
    "        for tag in soup.select('ul.petitionsView_info_list > li'):\n",
    "            a.append(tag.contents[1])\n",
    "            \n",
    "            \n",
    "        if len(a) != 0:\n",
    "            df1= pd.DataFrame({'start' : [a[1]],\n",
    "                              'end' : [a[2]], \n",
    "                              'category' : [a[0]],\n",
    "                              'count' : [count.text],\n",
    "                              'title' : [title.text],\n",
    "                              'content' : [content.text.strip()[0:13000]]\n",
    "                             })\n",
    "            \n",
    "            result = pd.concat([result,df1])\n",
    "            result.index = np.arange(len(result))\n",
    "            \n",
    "        if 1 % 60 == 0:\n",
    "            print(\"Sleep 90seconds.Count:\" + str(i)\n",
    "                 +\",   Local Time:\"\n",
    "                 + time.strftime('%Y-%m-%d', time.localtime(time.time()))\n",
    "                 + \" \" + time.strfime('%X', time.localtime(time.time()))\n",
    "                 + \",  Data Length:\" + str(len(result)))\n",
    "            \n",
    "            time.sleep(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98037ee7",
   "metadata": {},
   "source": [
    "## 크롤링 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf970eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357, 6)\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dc4831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>인권/성평등</td>\n",
       "      <td>267</td>\n",
       "      <td>서울지방병무청 탈의실에 설치된 CCTV에 대한 진상규명을 요구한다. 또한 인권위의 ...</td>\n",
       "      <td>본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>경제민주화</td>\n",
       "      <td>271</td>\n",
       "      <td>주식시장 활성화 및 소액(개미)투자자 보호</td>\n",
       "      <td>우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>행정</td>\n",
       "      <td>198</td>\n",
       "      <td>교정기관의 민낮</td>\n",
       "      <td>억울한 일로 국민청원을 신청합니다.\\n\\r\\n 저는 **구치소 **교도관입니다.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>안전/환경</td>\n",
       "      <td>170</td>\n",
       "      <td>미세먼지 저감 대책</td>\n",
       "      <td>미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다.\\r\\n우리 일상에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>교통/건축/국토</td>\n",
       "      <td>2,127</td>\n",
       "      <td>악질세입자 방지를 위한 세입자보호법을 재정해주세요.</td>\n",
       "      <td>저는 우선 아이셋의 부모입니다.\\r\\n식구가 많은편이고 아이들이 성장함에 따라 집이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start         end  category  count  \\\n",
       "0  2020-01-02  2020-02-01    인권/성평등    267   \n",
       "1  2020-01-02  2020-02-01     경제민주화    271   \n",
       "2  2020-01-02  2020-02-01        행정    198   \n",
       "3  2020-01-02  2020-02-01     안전/환경    170   \n",
       "4  2020-01-02  2020-02-01  교통/건축/국토  2,127   \n",
       "\n",
       "                                               title  \\\n",
       "0  서울지방병무청 탈의실에 설치된 CCTV에 대한 진상규명을 요구한다. 또한 인권위의 ...   \n",
       "1                            주식시장 활성화 및 소액(개미)투자자 보호   \n",
       "2                                           교정기관의 민낮   \n",
       "3                                         미세먼지 저감 대책   \n",
       "4                       악질세입자 방지를 위한 세입자보호법을 재정해주세요.   \n",
       "\n",
       "                                             content  \n",
       "0  본인은 2019년 8월 경 서울지방병무청 제1검사장 탈의실에서 믿을 수 없는 것을 ...  \n",
       "1  우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저...  \n",
       "2  억울한 일로 국민청원을 신청합니다.\\n\\r\\n 저는 **구치소 **교도관입니다.\\n...  \n",
       "3  미세먼지의 심각성은 이제 적극적인 대안을 요구 하고 있습니다.\\r\\n우리 일상에서 ...  \n",
       "4  저는 우선 아이셋의 부모입니다.\\r\\n식구가 많은편이고 아이들이 성장함에 따라 집이...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc872f0d",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7f51c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다. 하지만 투자매력이 없다고도 합니다.이렇게 말하는 이유가 어디 있습니까? 바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다.\\n\\r\\n지금은 투자매력이 없어서 그렇지,..우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과, 외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다. 그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다.\\n\\r\\n정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데,... 그렇지 못한 현실이 안타깝다고 생각합니다.\\r\\n국가가 지원해 돈 들이기가 어려우면,정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다. \\n\\r\\n그래서 저는 정부에 다음과 같이 청원합니다.\\r\\n주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서,...\\n\\r\\n첫째,주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오 \\n\\r\\n둘째,  코스닥 종목은 공매도 제외시켜 주세요.\\n\\r\\n공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다 \\n\\r\\n셋째, 거래시장의 주식거래세를 더 낮춰 주세요 \\n\\r\\n특히 개미(소액)투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다.\\n\\r\\n넷째, 중,장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요.\\n\\r\\n이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63048f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]',' ', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    text =re.sub('[^ ㄱ-ㅣ가-힣 0-9]+',' ', str(text))\n",
    "    return text\n",
    "\n",
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a3d284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다  하지만 투자매력이 없다고도 합니다 이렇게 말하는 이유가 어디 있습니까  바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다    지금은 투자매력이 없어서 그렇지 우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과  외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다  그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다    정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데  그렇지 못한 현실이 안타깝다고 생각합니다   국가가 지원해 돈 들이기가 어려우면 정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다     그래서 저는 정부에 다음과 같이 청원합니다   주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서    첫째 주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오    둘째   코스닥 종목은 공매도 제외시켜 주세요    공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다    셋째  거래시장의 주식거래세를 더 낮춰 주세요    특히 개미 소액 투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다    넷째  중 장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요    이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다 '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e92b9a",
   "metadata": {},
   "source": [
    "## 토크나이징 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6ee51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "df['content_token'] = df.content.apply(okt.nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ed396",
   "metadata": {},
   "source": [
    "## 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632a2b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start            object\n",
      "end              object\n",
      "category         object\n",
      "count             int64\n",
      "title            object\n",
      "content          object\n",
      "title_token      object\n",
      "content_token    object\n",
      "token_final      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "\n",
    "df['count'] = df['count'].replace({',':''},regex=True).apply(lambda x : int(x))\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df['label'] = df['count'].apply(lambda x : 'Yes' if x > 100 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9089c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df[['token_final','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4de6af",
   "metadata": {},
   "source": [
    "## 단어 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08650c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=9813, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(df_drop['token_final'], sg = 1, size = 100, window = 2, min_count =1, workers = 4)\n",
    "\n",
    "print(embedding_model)\n",
    "\n",
    "# Word2Vec(vocab = 43937, size =100, alpha= 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161b280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('남양주시', 0.9995100498199463), ('난', 0.9994927048683167), ('여행', 0.9994852542877197), ('물건', 0.9994851350784302), ('만약', 0.999478280544281), ('통', 0.9994648694992065), ('관계', 0.9994640350341797), ('스스로', 0.9994591474533081), ('유학생', 0.9994556903839111), ('소리', 0.9994490146636963)]\n"
     ]
    }
   ],
   "source": [
    "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7517597",
   "metadata": {},
   "source": [
    "## 임베딩 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39b511c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('남양주시', 0.9995100498199463), ('난', 0.9994927048683167), ('여행', 0.9994852542877197), ('물건', 0.9994851350784302), ('만약', 0.999478280544281), ('통', 0.9994648694992065), ('관계', 0.9994640350341797), ('스스로', 0.9994591474533081), ('유학생', 0.9994556903839111), ('소리', 0.9994490146636963)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v')\n",
    "\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"data/petitions_tokens_w2v\")\n",
    "\n",
    "model_result = loaded_model.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b151e81",
   "metadata": {},
   "source": [
    "## 데이터셋 분할 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e10c0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac = 0.8, random_state=rng)\n",
    "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('data/train.csv', index = False, encoding = 'utf-8-sig')\n",
    "val.to_csv('data/validation.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7bfc900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d289d",
   "metadata": {},
   "source": [
    "## Field 클래스 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6558cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']','',str(text))\n",
    "    text = text.split(',')\n",
    "    return text\n",
    "\n",
    "TEXT = Field(tokenize = tokenizer)\n",
    "LABEL = Field(sequential = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5138478a",
   "metadata": {},
   "source": [
    "##  데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fb82d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['초', ' 중', ' 고등학교', ' 의', ' 개학', ' 을', ' 순차', ' 적', ' 으로', ' 진행', ' 해주세요', ' 개학', ' 사회', ' 거리', ' 두기', ' 강조', ' 사람', ' 실정', ' 해외', ' 유입', ' 확', ' 진자', ' 계속', ' 산발', ' 확', ' 진자', ' 계속', ' 준비', ' 그게', ' 요', ' 개학', ' 아이', ' 더', ' 상황', ' 집단', ' 것', ' 수능', ' 일정', ' 등', ' 여러', ' 이유', ' 초', ' 중고', ' 개학', ' 상황', ' 라면', ' 고등', ' 개학', ' 후', ' 중등', ' 초등', ' 순', ' 순차', ' 개학', ' 진행', ' 생각', ' 제발', ' 아이', ' 생명', ' 건강', ' 최', ' 우선', ' 해'] Yes\n",
      "Validation: ['군산', ' 보복', ' 폭행', ' 피해자', ' 는', ' 억울합니다', ' 남자친구', ' 남자친구', ' 가족', ' 집앞', ' 치킨', ' 집', ' 약', ' 치킨', ' 주문', ' 중', ' 남자', ' 명', ' 우리', ' 앞', ' 술취해', ' 려니', ' 생각', ' 약', ' 다시', ' 우리', ' 갑자기', ' 남자친구', ' 이름', ' 호명', ' 것', ' 우린', ' 황해', ' 어디', ' 론', ' 것', ' 그때', ' 욕설', ' 계속', ' 본인', ' 후배', ' 싸움', ' 우리', ' 도대체', ' 이유', ' 왜', ' 소리', ' 대답', ' 욕', ' 뿐', ' 제', ' 신고', ' 폰', ' 영상', ' 촬영', ' 하자', ' 가해자', ' 폰', ' 어깨', ' 두번째', ' 가해자', ' 후배', ' 또한', ' 내부', ' 모욕', ' 방법', ' 어깨', ' 영상', ' 행해', ' 중간', ' 이', ' 남자친구', ' 어머니', ' 옆', ' 것', ' 가해자', ' 어머니', ' 도', ' 욕설', ' 일도', ' 남자친구', ' 형님', ' 또한', ' 우리', ' 가해자', ' 가미', ' 바람', ' 남자친구', ' 형수', ' 조카', ' 애', ' 명', ' 겁', ' 벌벌', ' 우린', ' 명분', ' 당', ' 지금', ' 시작', ' 영상', ' 어깨', ' 장면', ' 이안', ' 증거', ' 경찰', ' 중', ' 지역', ' 사회', ' 합의', ' 등', ' 나', ' 피해자', ' 등', ' 자리', ' 이름', ' 데', ' 알', ' 사람', ' 비아', ' 발언', ' 사람', ' 키', ' 도크', ' 덩', ' 치도', ' 커서', ' 저쪽', ' 가해자', ' 등', ' 어머니', ' 고소', ' 형사', ' 어머니', ' 이일', ' 말', ' 말', ' 나', ' 청문', ' 감사', ' 실가', ' 사관', ' 교채', ' 교채', ' 조사', ' 채', ' 형사', ' 도마', ' 찮', ' 검', ' 사실', ' 우리', ' 쪽', ' 걱정', ' 중간', ' 사관', ' 우리', ' 가해자', ' 기분', ' 상대방', ' 년전', ' 여고생', ' 살인', ' 용의자', ' 공범', ' 전이', ' 보복', ' 바', ' 어깨', ' 진단', ' 주', ' 수술', ' 생각', ' 정신과', ' 치료', ' 또한', ' 개월', ' 치료', ' 저', ' 보디빌더', ' 가정', ' 엄마', ' 일로', ' 선수', ' 생활', ' 꿈', ' 여기', ' 끝', ' 자살', ' 시도', ' 아이', ' 생각', ' 짓', ' 엄마', ' 우리', ' 아이', ' 생활', ' 남', ' 살', ' 나', ' 더', ' 사람', ' 이유', ' 명분', ' 비걸', ' 증거불충분', ' 가정', ' 피패', ' 정상', ' 생활', ' 법', ' 정황', ' 왜안', ' 경찰차', ' 신고', ' 당시', ' 불구', ' 가해자', ' 온몸', ' 문신', ' 채', ' 위퉁', ' 우리', ' 사지', ' 우린', ' 말', ' 진심', ' 사람', ' 살인', ' 전과', ' 때문', ' 진심', ' 결론', ' 증거불충분', ' 불기소', ' 니요', ' 죄', ' 단말', ' 입', ' 가해자', ' 무슨', ' 신고', ' 기소', ' 겁', ' 가해자', ' 왜', ' 피해자', ' 계속', ' 피해', ' 파출소', ' 경찰', ' 검사', ' 쪽', ' 우리말', ' 거', ' 낱낱', ' 부터', ' 불기소', ' 이유', ' 처분', ' 떼', ' 어보', ' 사관', ' 기전', ' 내용', ' 그게', ' 말', ' 왜', ' 입', ' 대한민국', ' 경찰', ' 검사', ' 어디', ' 신고', ' 피해자', ' 계속', ' 피해', ' 말입', ' 그냥', ' 말입', ' 제발', ' 제', ' 가족', ' 작년', ' 설날', ' 곧', ' 설날', ' 심장', ' 벌렁', ' 거려', ' 정신과', ' 약과', ' 정형외과', ' 약', ' 사건', ' 종결', ' 힘', ' 증거', ' 남자친구', ' 남자친구', ' 가족', ' 증인', ' 왜', ' 가요', ' 가해자', ' 절친', ' 치킨', ' 골', ' 손님', ' 치킨', ' 집사', ' 장님', ' 증인', ' 우리', ' 왜', ' 가요', ' 우린', ' 카메라', ' 보지', ' 가해자', ' 우리나라', ' 피해자', ' 위', ' 법입', ' 가해자', ' 위', ' 법입', ' 꼭', ' 사람', ' 반드시', ' 보복', ' 껍니', ' 왜', ' 피해자', ' 피해', ' 보복', ' 그때', ' 또', ' 신고', ' 경찰', ' 정말', ' 본인', ' 가족', ' 불기소', ' 종결', ' 지금', ' 사실', ' 말', ' 못', ' 얘기', ' 나', ' 피해자', ' 사건', ' 종결', ' 대한', ' 처음', ' 부텅', ' 잘못', ' 군산', ' 사관', ' 다시', ' 군산', ' 지역', ' 사회', ' 가해자', ' 아버지', ' 교도관', ' 셨', ' 저', ' 매번', ' 국민', ' 여러분', ' 저', ' 피해자', ' 더', ' 이상', ' 피해자', ' 보복', ' 더', ' 나', ' 신고', ' 경찰', ' 말씀', ' 네', ' 대답', ' 진술', ' 난', ' 고소', ' 참고인', ' 남자친구', ' 고소', ' 나', ' 참고인', ' 악몽', ' 국민', ' 여러분', ' 이일이', ' 내일', ' 생각', ' 제', ' 반드시', ' 부분', ' 가해자', ' 벌', ' 생각', ' 평상시', ' 행실', ' 아이', ' 함부로', ' 욕', ' 폭력', ' 군산', ' 사람', ' 이면', ' 손바닥', ' 알', ' 사람', ' 가해자', ' 지인', ' 가해자', ' 그냥', ' 해', ' 니', ' 깜', ' 방한', ' 번가', ' 말', ' 녹취내용', ' 첨부', ' 누락', ' 부분', ' 이', ' 합법', ' 라면', ' 아무나', ' 비걸', ' 욕', ' 티비', ' 안보', ' 곳', ' 죄', ' 것입', ' 경찰', ' 신고', ' 당시', ' 경찰', ' 가해자', ' 조회', ' 파출소', ' 저', ' 뭐', ' 게말', ' 국민', ' 여러분', ' 저', ' 이일이', ' 내일', ' 가족', ' 일이', ' 생각', ' 저', ' 힘', ' 백도', ' 조사', ' 제', ' 피해', ' 사실', ' 대한', ' 죄값', ' 생각', ' 저', ' 살인', ' 전과자', ' 그냥', ' 보복', ' 기전', ' 피해자', ' 국민', ' 여러분', ' 표', ' 표', ' 의'] Yes\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train,validation = TabularDataset.splits(\n",
    "    path = 'data/',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format='csv',\n",
    "    fields = [('text',TEXT),('label',LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text, train[0].label)\n",
    "print(\"Validation:\",validation[0].text, validation[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff678e",
   "metadata": {},
   "source": [
    "## 단어장 및 DataLoader 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "973e565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수와 차원: torch.Size([8957, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name='data/petitions_tokens_w2v')\n",
    "\n",
    "TEXT.build_vocab(train,vectors = vectors , min_freq = 1, max_size = None)\n",
    "\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(datasets = (train,validation),\n",
    "                                                   batch_size = 8,\n",
    "                                                   device = device,\n",
    "                                                   sort = False)\n",
    "\n",
    "print('임베딩 벡터의 개수와 차원: {}'.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4ed05",
   "metadata": {},
   "source": [
    "## TextCNN 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a9c7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self,vocab_built, emb_dim, dim_channel, kernel_wins,num_class):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built),emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1,dim_channel,(w,emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel,num_class)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        emb_x = self.embed(x)\n",
    "        emb_x = emb_x.unsqueeze(1)\n",
    "        \n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]\n",
    "        \n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]\n",
    "        \n",
    "        fc_x = torch.cat(pool_x,dim=1)\n",
    "        fc_x = fc_x.squeeze(-1)\n",
    "        fc_x = self.dropout(fc_x)\n",
    "        \n",
    "        logit = self.fc(fc_x)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb271a6f",
   "metadata": {},
   "source": [
    "## 모델 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4985890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    model.train()\n",
    "    corrects, train_loss = 0.0,0\n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label\n",
    "        text = torch.transpose(text,0,1)\n",
    "        target.data.sub_(1)\n",
    "        text,target = text.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logit= model(text)\n",
    "        \n",
    "        loss = F.cross_entropy(logit,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy= 100.0 * corrects / len(train_itr.dataset)\n",
    "    \n",
    "    return train_loss,accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7ed74",
   "metadata": {},
   "source": [
    "## 모델 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d8b203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device ,itr):\n",
    "    model. eval()\n",
    "    corrects, test_loss = 0.0, 0 \n",
    "    \n",
    "    \n",
    "    for batch in itr:\n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text,target = text.to(device),target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    test_loss/=len(itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    \n",
    "    return test_loss,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ed238",
   "metadata": {},
   "source": [
    "## 모델 학습 및 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d47fe6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(8957, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "Train Epoch: 1 \t Loss : 0.014175231876242514 \t Accuracy : 100.0%\n",
      "Valid Epoch: 1 \t Loss : 0.0006912005147044088 \t Accuracy : 100.0%\n",
      "model saves at 100.0 accuracy\n",
      "---------------------------------------------------------------------------------------\n",
      "Train Epoch: 2 \t Loss : 0.0007244417668968257 \t Accuracy : 100.0%\n",
      "Valid Epoch: 2 \t Loss : 0.00015109569296686793 \t Accuracy : 100.0%\n",
      "---------------------------------------------------------------------------------------\n",
      "Train Epoch: 3 \t Loss : 0.00029095296419902957 \t Accuracy : 100.0%\n",
      "Valid Epoch: 3 \t Loss : 6.940006114490016e-05 \t Accuracy : 100.0%\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10, [3,4,5], 2).to(device)\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "best_test_acc = -1\n",
    "\n",
    "for epoch in range(1,3+1):\n",
    "    \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer)\n",
    "    \n",
    "    print('Train Epoch: {} \\t Loss : {} \\t Accuracy : {}%'.format(epoch,tr_loss,tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    \n",
    "    print('Valid Epoch: {} \\t Loss : {} \\t Accuracy : {}%'.format(epoch,val_loss,val_acc))\n",
    "    \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(),\"TextCNN_Best_Validation\")\n",
    "        \n",
    "    print('---------------------------------------------------------------------------------------')\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557ea4b",
   "metadata": {},
   "source": [
    "## 결과가 매우 이상하게 나왔음 .....\n",
    "### 책에서는 60프로 대가 나오는데 왜 내껀 이모양인지 모르겠음  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba9e4ad",
   "metadata": {},
   "source": [
    "### 주제확장\n",
    "\n",
    "1. 우러별로 가장 많이 등장한 단어들을 추출하여 국민 청원 기반 우러별 이슈를 작성할 수 있습니다. \n",
    "2. 분류 대상을 카테고리로 변경하여 카테고리 분류를 할 수 있습니다. \n",
    "3. 유사한 청원들을 그룹화해 해당 청원의 총 참여인원이 며ㅑㅊ 명이 될지 분석이 가능합니다. 예를 들어 미세먼지와 관련된 비슷한 청원 3개가 각각 10만명, 6만명, 4만명 참여인원을 기록했다며, 이 세개 글은 그룹화되었을 때 20만명의 동의를 얻을 수 있다는 정보입니다. \n",
    "4. 작성자가 글을 작성할 때, 해당 글과 기존에 작성된 청원 글과의 유사도를 구해 가장 유사한 청원을 추천하는 추천 시스템을 구현할 수 있습니다. \n",
    "5. 다양한 청원 중에는 국민청원보다 국민신문고, 지자체 민원 등 다른 기관을 이용하는 편이 더 효율적인 사연들이 있습니다. 따라서 이러한 청원이 등록되었을 때, 청원 내용에 따른 적합한 기관에 대한 가이드를 제공할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e0698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_hy",
   "language": "python",
   "name": "pytorch_hy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
